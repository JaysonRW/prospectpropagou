# ü§ñ Integra√ß√£o com Code LLM

Este guia detalha como integrar a Automa√ß√£o de Prospec√ß√£o com Code LLMs para an√°lise inteligente, gera√ß√£o de conte√∫do e otimiza√ß√£o de campanhas.

## üéØ Vis√£o Geral

### Casos de Uso com Code LLM
1. **An√°lise de Dados**: Insights sobre neg√≥cios coletados
2. **Gera√ß√£o de Mensagens**: Mensagens personalizadas por segmento
3. **Otimiza√ß√£o de Campanhas**: An√°lise de performance e sugest√µes
4. **Classifica√ß√£o Autom√°tica**: Categoriza√ß√£o inteligente de neg√≥cios
5. **Detec√ß√£o de Padr√µes**: Identifica√ß√£o de oportunidades de mercado

### Arquitetura de Integra√ß√£o
```
Automa√ß√£o de Prospec√ß√£o ‚Üí API/Database ‚Üí Code LLM ‚Üí Insights/Content
                                      ‚Üì
                              Feedback Loop para Otimiza√ß√£o
```

## üîß Configura√ß√£o B√°sica

### 1. Instalar Depend√™ncias Adicionais
```bash
# Ativar ambiente virtual
source venv/bin/activate

# Instalar bibliotecas para LLM
pip install openai anthropic langchain tiktoken
```

### 2. Configurar Vari√°veis de Ambiente
```bash
# Adicionar ao arquivo .env
nano .env
```

```env
# Configura√ß√µes de LLM
OPENAI_API_KEY=sua_chave_openai_aqui
ANTHROPIC_API_KEY=sua_chave_anthropic_aqui
LLM_PROVIDER=openai  # ou anthropic, local, etc.
LLM_MODEL=gpt-4  # ou claude-3, llama-2, etc.
LLM_MAX_TOKENS=2000
LLM_TEMPERATURE=0.7

# Configura√ß√µes espec√≠ficas
ENABLE_LLM_ANALYSIS=true
ENABLE_AUTO_MESSAGE_GENERATION=true
LLM_ANALYSIS_INTERVAL=3600  # segundos
```

### 3. Criar M√≥dulo de Integra√ß√£o LLM
```bash
# Criar arquivo para integra√ß√£o
nano llm_integration.py
```

```python
# llm_integration.py
import os
import json
import logging
from typing import List, Dict, Optional
from datetime import datetime
import openai
from anthropic import Anthropic
from models import Business, MessageLog, SessionLocal

logger = logging.getLogger(__name__)

class LLMIntegration:
    def __init__(self):
        self.provider = os.getenv('LLM_PROVIDER', 'openai')
        self.model = os.getenv('LLM_MODEL', 'gpt-4')
        self.max_tokens = int(os.getenv('LLM_MAX_TOKENS', 2000))
        self.temperature = float(os.getenv('LLM_TEMPERATURE', 0.7))
        
        if self.provider == 'openai':
            openai.api_key = os.getenv('OPENAI_API_KEY')
        elif self.provider == 'anthropic':
            self.anthropic = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
    
    def generate_completion(self, prompt: str) -> str:
        """Gera resposta usando o LLM configurado"""
        try:
            if self.provider == 'openai':
                response = openai.ChatCompletion.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=self.max_tokens,
                    temperature=self.temperature
                )
                return response.choices[0].message.content
            
            elif self.provider == 'anthropic':
                response = self.anthropic.messages.create(
                    model=self.model,
                    max_tokens=self.max_tokens,
                    temperature=self.temperature,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            
        except Exception as e:
            logger.error(f"Erro ao gerar completion: {e}")
            return None
    
    def analyze_business_data(self, businesses: List[Business]) -> Dict:
        """Analisa dados de neg√≥cios usando LLM"""
        
        # Preparar dados para an√°lise
        business_data = []
        for business in businesses:
            business_data.append({
                'name': business.name,
                'category': business.category,
                'rating': business.rating,
                'reviews_count': business.reviews_count,
                'address': business.address,
                'phone': business.phone
            })
        
        prompt = f"""
        Analise os seguintes dados de {len(businesses)} neg√≥cios coletados em Curitiba:
        
        {json.dumps(business_data, indent=2, ensure_ascii=False)}
        
        Forne√ßa uma an√°lise detalhada incluindo:
        
        1. **Distribui√ß√£o por Categorias**: Quais categorias s√£o mais comuns?
        2. **An√°lise de Qualidade**: Padr√µes nas avalia√ß√µes e n√∫mero de reviews
        3. **Oportunidades de Mercado**: Segmentos com potencial
        4. **Recomenda√ß√µes de Abordagem**: Como abordar cada categoria
        5. **Insights Geogr√°ficos**: Padr√µes por regi√£o/bairro
        6. **Timing Recomendado**: Melhores hor√°rios para contato por categoria
        
        Responda em formato JSON estruturado.
        """
        
        response = self.generate_completion(prompt)
        
        try:
            return json.loads(response)
        except:
            return {"analysis": response, "structured": False}
    
    def generate_personalized_message(self, business: Business, campaign_type: str = "prospeccao") -> str:
        """Gera mensagem personalizada para um neg√≥cio espec√≠fico"""
        
        prompt = f"""
        Crie uma mensagem de {campaign_type} profissional e personalizada para:
        
        **Neg√≥cio**: {business.name}
        **Categoria**: {business.category}
        **Localiza√ß√£o**: {business.address}
        **Avalia√ß√£o**: {business.rating} estrelas ({business.reviews_count} avalia√ß√µes)
        
        **Diretrizes**:
        - M√°ximo 160 caracteres (SMS/WhatsApp)
        - Tom profissional mas amig√°vel
        - Mencionar algo espec√≠fico sobre o neg√≥cio
        - Incluir proposta de valor clara
        - Personalizar para a categoria do neg√≥cio
        - Incluir call-to-action
        
        **Contexto**: Somos uma empresa de marketing digital em Curitiba oferecendo servi√ßos de automa√ß√£o e prospec√ß√£o.
        
        Retorne apenas a mensagem, sem explica√ß√µes adicionais.
        """
        
        return self.generate_completion(prompt)
    
    def optimize_campaign_strategy(self, campaign_results: Dict) -> Dict:
        """Analisa resultados de campanha e sugere otimiza√ß√µes"""
        
        prompt = f"""
        Analise os resultados da campanha de prospec√ß√£o:
        
        {json.dumps(campaign_results, indent=2, ensure_ascii=False)}
        
        Forne√ßa recomenda√ß√µes de otimiza√ß√£o para:
        
        1. **Taxa de Resposta**: Como melhorar o engajamento
        2. **Segmenta√ß√£o**: Ajustes na segmenta√ß√£o de p√∫blico
        3. **Timing**: Otimiza√ß√£o de hor√°rios de envio
        4. **Mensagens**: Melhorias no conte√∫do das mensagens
        5. **Frequ√™ncia**: Ajustes na frequ√™ncia de contato
        6. **Pr√≥ximos Passos**: Estrat√©gias para follow-up
        
        Responda em formato JSON com recomenda√ß√µes espec√≠ficas e m√©tricas esperadas.
        """
        
        response = self.generate_completion(prompt)
        
        try:
            return json.loads(response)
        except:
            return {"recommendations": response, "structured": False}
    
    def classify_business_potential(self, business: Business) -> Dict:
        """Classifica o potencial de convers√£o de um neg√≥cio"""
        
        prompt = f"""
        Avalie o potencial de convers√£o deste neg√≥cio para servi√ßos de marketing digital:
        
        **Nome**: {business.name}
        **Categoria**: {business.category}
        **Avalia√ß√£o**: {business.rating}/5 ({business.reviews_count} reviews)
        **Localiza√ß√£o**: {business.address}
        
        Classifique em:
        - **Potencial**: Alto/M√©dio/Baixo
        - **Prioridade**: 1-10
        - **Abordagem Recomendada**: Estrat√©gia espec√≠fica
        - **Proposta de Valor**: O que destacar
        - **Obje√ß√µes Prov√°veis**: Poss√≠veis resist√™ncias
        - **Timing Ideal**: Melhor momento para contato
        
        Responda em formato JSON.
        """
        
        response = self.generate_completion(prompt)
        
        try:
            return json.loads(response)
        except:
            return {"classification": response, "structured": False}

# Inst√¢ncia global
llm = LLMIntegration()
```

## üìä Implementa√ß√£o de An√°lises

### 1. An√°lise Autom√°tica de Dados Coletados
```python
# Adicionar ao app.py
from llm_integration import llm

@app.route('/api/llm_analysis')
def get_llm_analysis():
    """Endpoint para an√°lise LLM dos dados"""
    if not os.getenv('ENABLE_LLM_ANALYSIS', 'false').lower() == 'true':
        return jsonify({'error': 'An√°lise LLM n√£o habilitada'})
    
    db = SessionLocal()
    try:
        # Buscar neg√≥cios recentes
        businesses = db.query(Business).limit(100).all()
        
        if not businesses:
            return jsonify({'error': 'Nenhum dado para an√°lise'})
        
        # Gerar an√°lise
        analysis = llm.analyze_business_data(businesses)
        
        return jsonify({
            'success': True,
            'analysis': analysis,
            'businesses_analyzed': len(businesses),
            'generated_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Erro na an√°lise LLM: {e}")
        return jsonify({'error': str(e)})
    finally:
        db.close()
```

### 2. Gera√ß√£o Autom√°tica de Mensagens
```python
@app.route('/api/generate_messages', methods=['POST'])
def generate_messages():
    """Gera mensagens personalizadas usando LLM"""
    if not os.getenv('ENABLE_AUTO_MESSAGE_GENERATION', 'false').lower() == 'true':
        return jsonify({'error': 'Gera√ß√£o autom√°tica n√£o habilitada'})
    
    data = request.json
    category_filter = data.get('category_filter')
    max_messages = int(data.get('max_messages', 10))
    
    db = SessionLocal()
    try:
        # Buscar neg√≥cios para gerar mensagens
        query = db.query(Business).filter(Business.phone.isnot(None))
        
        if category_filter:
            query = query.filter(Business.category.contains(category_filter))
        
        businesses = query.limit(max_messages).all()
        
        generated_messages = []
        
        for business in businesses:
            # Gerar mensagem personalizada
            message = llm.generate_personalized_message(business)
            
            # Classificar potencial
            potential = llm.classify_business_potential(business)
            
            generated_messages.append({
                'business_id': business.id,
                'business_name': business.name,
                'category': business.category,
                'message': message,
                'potential': potential,
                'phone': business.phone
            })
        
        return jsonify({
            'success': True,
            'messages': generated_messages,
            'total_generated': len(generated_messages)
        })
        
    except Exception as e:
        logger.error(f"Erro na gera√ß√£o de mensagens: {e}")
        return jsonify({'error': str(e)})
    finally:
        db.close()
```

## üéØ Casos de Uso Avan√ßados

### 1. An√°lise de Sentimento de Respostas
```python
def analyze_response_sentiment(response_text: str) -> Dict:
    """Analisa sentimento das respostas recebidas"""
    
    prompt = f"""
    Analise o sentimento e inten√ß√£o da seguinte resposta de um prospect:
    
    "{response_text}"
    
    Classifique:
    - **Sentimento**: Positivo/Neutro/Negativo
    - **Interesse**: Alto/M√©dio/Baixo/Nenhum
    - **Pr√≥xima A√ß√£o**: Recomenda√ß√£o espec√≠fica
    - **Urg√™ncia**: Imediata/M√©dia/Baixa
    - **Obje√ß√µes**: Identificar resist√™ncias
    
    Responda em formato JSON.
    """
    
    return llm.generate_completion(prompt)
```

### 2. Otimiza√ß√£o de Hor√°rios de Envio
```python
def optimize_sending_schedule(historical_data: List[Dict]) -> Dict:
    """Otimiza hor√°rios de envio baseado em dados hist√≥ricos"""
    
    prompt = f"""
    Baseado nos dados hist√≥ricos de campanhas:
    
    {json.dumps(historical_data, indent=2)}
    
    Recomende:
    - **Melhores Hor√°rios**: Por dia da semana
    - **Hor√°rios por Categoria**: Segmenta√ß√£o por tipo de neg√≥cio
    - **Frequ√™ncia Ideal**: Intervalo entre mensagens
    - **Sazonalidade**: Padr√µes mensais/sazonais
    
    Forne√ßa cronograma otimizado em formato JSON.
    """
    
    return llm.generate_completion(prompt)
```

### 3. Gera√ß√£o de Follow-up Inteligente
```python
def generate_followup_sequence(business: Business, interaction_history: List[Dict]) -> List[str]:
    """Gera sequ√™ncia de follow-up personalizada"""
    
    prompt = f"""
    Crie uma sequ√™ncia de 3 mensagens de follow-up para:
    
    **Neg√≥cio**: {business.name} ({business.category})
    **Hist√≥rico de Intera√ß√µes**: {json.dumps(interaction_history)}
    
    Cada mensagem deve:
    - Ser progressivamente mais espec√≠fica
    - Abordar poss√≠veis obje√ß√µes
    - Incluir social proof relevante
    - Ter call-to-action claro
    
    Retorne array JSON com as 3 mensagens.
    """
    
    response = llm.generate_completion(prompt)
    
    try:
        return json.loads(response)
    except:
        return [response]
```

## üîÑ Automa√ß√£o com LLM

### 1. An√°lise Autom√°tica Peri√≥dica
```python
# Criar arquivo de tarefa autom√°tica
# nano llm_tasks.py

import schedule
import time
from llm_integration import llm
from models import Business, SessionLocal

def automated_analysis():
    """Executa an√°lise autom√°tica dos dados"""
    logger.info("Iniciando an√°lise autom√°tica com LLM")
    
    db = SessionLocal()
    try:
        # Buscar dados recentes
        businesses = db.query(Business).limit(200).all()
        
        if businesses:
            # Gerar an√°lise
            analysis = llm.analyze_business_data(businesses)
            
            # Salvar an√°lise em arquivo
            with open(f'logs/llm_analysis_{datetime.now().strftime("%Y%m%d_%H%M")}.json', 'w') as f:
                json.dump(analysis, f, indent=2, ensure_ascii=False)
            
            logger.info(f"An√°lise conclu√≠da para {len(businesses)} neg√≥cios")
        
    except Exception as e:
        logger.error(f"Erro na an√°lise autom√°tica: {e}")
    finally:
        db.close()

# Agendar an√°lise a cada 6 horas
schedule.every(6).hours.do(automated_analysis)

def run_scheduler():
    while True:
        schedule.run_pending()
        time.sleep(60)

if __name__ == "__main__":
    run_scheduler()
```

### 2. Integra√ß√£o com Webhook para Respostas
```python
@app.route('/webhook/whatsapp_response', methods=['POST'])
def handle_whatsapp_response():
    """Processa respostas do WhatsApp com an√°lise LLM"""
    
    data = request.json
    phone = data.get('phone')
    message = data.get('message')
    
    if not phone or not message:
        return jsonify({'error': 'Dados incompletos'})
    
    # Analisar sentimento da resposta
    sentiment_analysis = llm.analyze_response_sentiment(message)
    
    # Buscar neg√≥cio correspondente
    db = SessionLocal()
    business = db.query(Business).filter(Business.phone == phone).first()
    
    if business:
        # Gerar resposta autom√°tica baseada no sentimento
        if sentiment_analysis.get('interest') == 'Alto':
            # Agendar follow-up personalizado
            followup = llm.generate_followup_sequence(business, [{'message': message, 'timestamp': datetime.now()}])
            
            # Salvar para processamento posterior
            # ... implementar l√≥gica de agendamento
    
    db.close()
    
    return jsonify({'success': True, 'analysis': sentiment_analysis})
```

## üìà Dashboard com Insights LLM

### 1. Endpoint para Dashboard
```python
@app.route('/api/llm_insights')
def get_llm_insights():
    """Retorna insights gerados por LLM para dashboard"""
    
    db = SessionLocal()
    try:
        # Estat√≠sticas b√°sicas
        total_businesses = db.query(Business).count()
        categories = db.query(Business.category).distinct().all()
        
        # Gerar insights r√°pidos
        quick_insights = llm.generate_completion(f"""
        Baseado em {total_businesses} neg√≥cios coletados em {len(categories)} categorias diferentes,
        forne√ßa 5 insights r√°pidos sobre oportunidades de mercado em Curitiba.
        
        Responda em formato de lista JSON com insights concisos.
        """)
        
        return jsonify({
            'total_businesses': total_businesses,
            'categories_count': len(categories),
            'quick_insights': json.loads(quick_insights) if quick_insights else [],
            'generated_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({'error': str(e)})
    finally:
        db.close()
```

### 2. Template HTML para Insights
```html
<!-- Adicionar ao template base.html -->
<div class="llm-insights-section" id="llm-insights">
    <h3>ü§ñ Insights Inteligentes</h3>
    <div id="insights-content">
        <p>Carregando insights...</p>
    </div>
    <button onclick="refreshInsights()" class="btn btn-primary">
        Atualizar Insights
    </button>
</div>

<script>
function loadLLMInsights() {
    fetch('/api/llm_insights')
        .then(response => response.json())
        .then(data => {
            const content = document.getElementById('insights-content');
            
            if (data.quick_insights) {
                let html = '<ul class="insights-list">';
                data.quick_insights.forEach(insight => {
                    html += `<li class="insight-item">${insight}</li>`;
                });
                html += '</ul>';
                content.innerHTML = html;
            }
        })
        .catch(error => {
            console.error('Erro ao carregar insights:', error);
        });
}

function refreshInsights() {
    document.getElementById('insights-content').innerHTML = '<p>Gerando novos insights...</p>';
    loadLLMInsights();
}

// Carregar insights ao carregar a p√°gina
document.addEventListener('DOMContentLoaded', loadLLMInsights);
</script>
```

## üîß Configura√ß√£o para Diferentes Provedores

### 1. OpenAI GPT
```python
# Configura√ß√£o espec√≠fica para OpenAI
OPENAI_CONFIG = {
    'api_key': os.getenv('OPENAI_API_KEY'),
    'model': 'gpt-4',
    'max_tokens': 2000,
    'temperature': 0.7,
    'top_p': 1,
    'frequency_penalty': 0,
    'presence_penalty': 0
}
```

### 2. Anthropic Claude
```python
# Configura√ß√£o espec√≠fica para Claude
ANTHROPIC_CONFIG = {
    'api_key': os.getenv('ANTHROPIC_API_KEY'),
    'model': 'claude-3-sonnet-20240229',
    'max_tokens': 2000,
    'temperature': 0.7
}
```

### 3. LLM Local (Ollama)
```python
# Configura√ß√£o para LLM local
import requests

class LocalLLM:
    def __init__(self, base_url="http://localhost:11434"):
        self.base_url = base_url
        self.model = os.getenv('LOCAL_LLM_MODEL', 'llama2')
    
    def generate_completion(self, prompt: str) -> str:
        response = requests.post(
            f"{self.base_url}/api/generate",
            json={
                'model': self.model,
                'prompt': prompt,
                'stream': False
            }
        )
        
        if response.status_code == 200:
            return response.json()['response']
        return None
```

## üìä M√©tricas e Monitoramento

### 1. Tracking de Performance LLM
```python
class LLMMetrics:
    def __init__(self):
        self.metrics = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'average_response_time': 0,
            'token_usage': 0,
            'cost_tracking': 0
        }
    
    def track_request(self, success: bool, response_time: float, tokens: int, cost: float):
        self.metrics['total_requests'] += 1
        
        if success:
            self.metrics['successful_requests'] += 1
        else:
            self.metrics['failed_requests'] += 1
        
        # Calcular m√©dia de tempo de resposta
        current_avg = self.metrics['average_response_time']
        total_requests = self.metrics['total_requests']
        self.metrics['average_response_time'] = (current_avg * (total_requests - 1) + response_time) / total_requests
        
        self.metrics['token_usage'] += tokens
        self.metrics['cost_tracking'] += cost
    
    def get_metrics(self) -> Dict:
        return self.metrics.copy()

# Inst√¢ncia global de m√©tricas
llm_metrics = LLMMetrics()
```

### 2. Dashboard de M√©tricas LLM
```python
@app.route('/api/llm_metrics')
def get_llm_metrics():
    """Retorna m√©tricas de uso do LLM"""
    return jsonify(llm_metrics.get_metrics())
```

## üöÄ Exemplos Pr√°ticos

### 1. Script de An√°lise Completa
```python
# analyze_campaign.py
from llm_integration import llm
from models import Business, MessageLog, SessionLocal

def run_complete_analysis():
    """Executa an√°lise completa com LLM"""
    
    db = SessionLocal()
    
    # 1. Analisar dados de neg√≥cios
    businesses = db.query(Business).all()
    business_analysis = llm.analyze_business_data(businesses)
    
    # 2. Analisar performance de campanhas
    messages = db.query(MessageLog).all()
    campaign_data = [
        {
            'business_name': msg.business_name,
            'sent_at': msg.sent_at.isoformat() if msg.sent_at else None,
            'success': msg.message_sent,
            'error': msg.error_message
        }
        for msg in messages
    ]
    
    campaign_analysis = llm.optimize_campaign_strategy({'messages': campaign_data})
    
    # 3. Gerar relat√≥rio consolidado
    report = {
        'business_analysis': business_analysis,
        'campaign_analysis': campaign_analysis,
        'generated_at': datetime.now().isoformat(),
        'total_businesses': len(businesses),
        'total_messages': len(messages)
    }
    
    # Salvar relat√≥rio
    with open(f'reports/llm_analysis_{datetime.now().strftime("%Y%m%d")}.json', 'w') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print("An√°lise completa conclu√≠da!")
    return report

if __name__ == "__main__":
    run_complete_analysis()
```

### 2. Gera√ß√£o de Campanha Inteligente
```python
# smart_campaign.py
def create_smart_campaign(target_category: str = None):
    """Cria campanha inteligente usando LLM"""
    
    db = SessionLocal()
    
    # Buscar neg√≥cios alvo
    query = db.query(Business).filter(Business.phone.isnot(None))
    if target_category:
        query = query.filter(Business.category.contains(target_category))
    
    businesses = query.limit(50).all()
    
    campaign_messages = []
    
    for business in businesses:
        # Classificar potencial
        potential = llm.classify_business_potential(business)
        
        # Gerar mensagem apenas para alto potencial
        if potential.get('potential') == 'Alto':
            message = llm.generate_personalized_message(business)
            
            campaign_messages.append({
                'business': business,
                'message': message,
                'potential': potential,
                'priority': potential.get('priority', 5)
            })
    
    # Ordenar por prioridade
    campaign_messages.sort(key=lambda x: x['priority'], reverse=True)
    
    print(f"Campanha criada com {len(campaign_messages)} mensagens de alta prioridade")
    
    return campaign_messages

if __name__ == "__main__":
    campaign = create_smart_campaign("restaurante")
    
    # Exibir primeiras 5 mensagens
    for i, item in enumerate(campaign[:5]):
        print(f"\n{i+1}. {item['business'].name}")
        print(f"Mensagem: {item['message']}")
        print(f"Prioridade: {item['priority']}")
```

---

**Integra√ß√£o com Code LLM configurada! ü§ñ**

Agora voc√™ pode:
- ‚úÖ Analisar dados de neg√≥cios automaticamente
- ‚úÖ Gerar mensagens personalizadas
- ‚úÖ Otimizar campanhas com IA
- ‚úÖ Classificar potencial de convers√£o
- ‚úÖ Automatizar follow-ups inteligentes
- ‚úÖ Monitorar performance com m√©tricas

**Pr√≥ximos passos**: [Guia de Uso](USAGE.md) | [Troubleshooting](../README.md#troubleshooting)
